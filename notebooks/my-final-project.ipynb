{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:32:04.348271Z",
     "iopub.status.busy": "2024-03-27T20:32:04.348029Z",
     "iopub.status.idle": "2024-03-27T20:32:19.083287Z",
     "shell.execute_reply": "2024-03-27T20:32:19.082246Z",
     "shell.execute_reply.started": "2024-03-27T20:32:04.348249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:32:19.085416Z",
     "iopub.status.busy": "2024-03-27T20:32:19.085118Z",
     "iopub.status.idle": "2024-03-27T20:33:26.498049Z",
     "shell.execute_reply": "2024-03-27T20:33:26.497118Z",
     "shell.execute_reply.started": "2024-03-27T20:32:19.085387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# Specify the Google Drive URL\n",
    "url = \"https://drive.google.com/uc?id=1A2IU8Sgea1h3fYLpYtFb2v7NYdMjvEhU\"\n",
    "output = \"mycheckpointfile\"  # Specify the output filename0\n",
    "gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:33:51.593475Z",
     "iopub.status.busy": "2024-03-27T20:33:51.592964Z",
     "iopub.status.idle": "2024-03-27T20:33:52.544746Z",
     "shell.execute_reply": "2024-03-27T20:33:52.543347Z",
     "shell.execute_reply.started": "2024-03-27T20:33:51.593445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:33:58.507075Z",
     "iopub.status.busy": "2024-03-27T20:33:58.506215Z",
     "iopub.status.idle": "2024-03-27T20:34:13.159447Z",
     "shell.execute_reply": "2024-03-27T20:34:13.158296Z",
     "shell.execute_reply.started": "2024-03-27T20:33:58.507036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Specify the path to the downloaded tar file\n",
    "tar_file_path = \"mycheckpointfile\"\n",
    "\n",
    "# Specify the extraction directory\n",
    "extract_dir = \"extracted_data\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Extract the contents of the tar file\n",
    "with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
    "    tar_ref.extractall(extract_dir)\n",
    "\n",
    "# Check the extracted files\n",
    "extracted_files = os.listdir(extract_dir)\n",
    "print(\"Extracted files:\", extracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:34:17.896110Z",
     "iopub.status.busy": "2024-03-27T20:34:17.895511Z",
     "iopub.status.idle": "2024-03-27T20:34:18.361752Z",
     "shell.execute_reply": "2024-03-27T20:34:18.360716Z",
     "shell.execute_reply.started": "2024-03-27T20:34:17.896080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "nii_img = nib.load('/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/BRATS_484.nii.gz')\n",
    "img_shape = nii_img.get_fdata().shape\n",
    "\n",
    "print(\"Shape of NIfTI image:\", img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:34:29.431527Z",
     "iopub.status.busy": "2024-03-27T20:34:29.431128Z",
     "iopub.status.idle": "2024-03-27T20:34:29.438117Z",
     "shell.execute_reply": "2024-03-27T20:34:29.437314Z",
     "shell.execute_reply.started": "2024-03-27T20:34:29.431496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_dir = \"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(image_dir)\n",
    "\n",
    "# Count the number of files\n",
    "total_images = len(files)\n",
    "\n",
    "print(\"Total number of images:\", total_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:34:36.145254Z",
     "iopub.status.busy": "2024-03-27T20:34:36.144887Z",
     "iopub.status.idle": "2024-03-27T20:34:36.156832Z",
     "shell.execute_reply": "2024-03-27T20:34:36.155967Z",
     "shell.execute_reply.started": "2024-03-27T20:34:36.145226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory path\n",
    "image_dir = \"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(image_dir)\n",
    "\n",
    "# Extract numbers from filenames and convert them to integers\n",
    "existing_numbers = []\n",
    "for filename in files:\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) == 2 and parts[0] == 'BRATS' and parts[1].split('.')[0].isdigit():\n",
    "        existing_numbers.append(int(parts[1].split('.')[0]))\n",
    "\n",
    "# Expected range of numbers\n",
    "expected_numbers = range(1, 496)\n",
    "\n",
    "# Find missing numbers\n",
    "missing_numbers = [num for num in expected_numbers if num not in existing_numbers]\n",
    "\n",
    "# Print missing images\n",
    "if missing_numbers:\n",
    "    print(\"Missing images:\")\n",
    "    for num in missing_numbers:\n",
    "        print(f\"BRATS_{num:03d}.nii.gz\")\n",
    "else:\n",
    "    print(\"No images are missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:34:44.164141Z",
     "iopub.status.busy": "2024-03-27T20:34:44.163789Z",
     "iopub.status.idle": "2024-03-27T20:34:45.764328Z",
     "shell.execute_reply": "2024-03-27T20:34:45.763305Z",
     "shell.execute_reply.started": "2024-03-27T20:34:44.164113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the NIfTI image\n",
    "nii_img = nib.load('/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/BRATS_243.nii.gz')\n",
    "img_data = nii_img.get_fdata()\n",
    "\n",
    "# Get the shape of the image data\n",
    "img_shape = img_data.shape\n",
    "\n",
    "# Define the number of channels\n",
    "num_channels = img_shape[-1]\n",
    "\n",
    "# Visualize each channel\n",
    "fig, axes = plt.subplots(1, num_channels, figsize=(5*num_channels, 5))\n",
    "\n",
    "for i in range(num_channels):\n",
    "    # Show the i-th channel\n",
    "    axes[i].imshow(img_data[:, :, 77, i], cmap='gray')\n",
    "    axes[i].set_title(f'Channel {i+1}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:35:04.719943Z",
     "iopub.status.busy": "2024-03-27T20:35:04.719134Z",
     "iopub.status.idle": "2024-03-27T20:35:46.738394Z",
     "shell.execute_reply": "2024-03-27T20:35:46.737313Z",
     "shell.execute_reply.started": "2024-03-27T20:35:04.719905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/BRATS_120.nii.gz\"\n",
    "label_path = \"/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/BRATS_120.nii.gz\"\n",
    "\n",
    "# Load the image and label data\n",
    "img = nib.load(image_path)\n",
    "label_img = nib.load(label_path)\n",
    "\n",
    "# Get the image and label data arrays\n",
    "image_data = img.get_fdata()\n",
    "label_data = label_img.get_fdata()\n",
    "\n",
    "# Use only the first channel (assuming 0-indexing)\n",
    "image_data_single_channel = image_data[..., 0]\n",
    "\n",
    "# Plot each slice with label overlay\n",
    "for slice_index in range(image_data.shape[2]):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot the original MRI image for the single channel and current slice\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_data_single_channel[:, :, slice_index], cmap='gray')\n",
    "    plt.title(f\"Slice {slice_index+1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the overlay of the label data in red\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image_data_single_channel[:, :, slice_index], cmap='gray')\n",
    "    plt.imshow(label_data[:, :, slice_index], alpha=0.5, cmap='Reds')\n",
    "    plt.title(f\"Slice {slice_index+1} with Label Overlay\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:36:34.849074Z",
     "iopub.status.busy": "2024-03-27T20:36:34.848385Z",
     "iopub.status.idle": "2024-03-27T20:36:36.566178Z",
     "shell.execute_reply": "2024-03-27T20:36:36.565306Z",
     "shell.execute_reply.started": "2024-03-27T20:36:34.849044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to image and label files\n",
    "image_path = \"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/BRATS_120.nii.gz\"\n",
    "label_path = \"/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/BRATS_120.nii.gz\"\n",
    "\n",
    "# Load the image and label data\n",
    "img = nib.load(image_path)\n",
    "label_img = nib.load(label_path)\n",
    "\n",
    "# Get the image and label data arrays\n",
    "image_data = img.get_fdata()\n",
    "label_data = label_img.get_fdata()\n",
    "\n",
    "# Plot each channel with label overlay\n",
    "for channel in range(image_data.shape[-1]):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot the original MRI image for the channel\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_data[..., 77, channel], cmap='gray')  # Adjust the slice index as needed\n",
    "    plt.title(f\"Channel {channel+1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the overlay of the label data in red\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image_data[..., 77, channel], cmap='gray')  # Adjust the slice index as needed\n",
    "    plt.imshow(label_data[..., 77], alpha=0.5, cmap='Reds')  # Assuming label_data is 3D\n",
    "    plt.title(f\"Channel {channel+1} with Label Overlay\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:36:56.860592Z",
     "iopub.status.busy": "2024-03-27T20:36:56.860117Z",
     "iopub.status.idle": "2024-03-27T20:36:58.027945Z",
     "shell.execute_reply": "2024-03-27T20:36:58.027120Z",
     "shell.execute_reply.started": "2024-03-27T20:36:56.860564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "# Paths to image and label directories\n",
    "image_dir = \"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/\"\n",
    "label_dir = \"/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/\"\n",
    "\n",
    "# Get image and label files, ignoring hidden files\n",
    "image_files = [f for f in sorted(os.listdir(image_dir)) if not f.startswith('.')][:200]\n",
    "label_files = [f for f in sorted(os.listdir(label_dir)) if not f.startswith('.')][:200]\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:37:04.532268Z",
     "iopub.status.busy": "2024-03-27T20:37:04.531401Z",
     "iopub.status.idle": "2024-03-27T20:40:28.362220Z",
     "shell.execute_reply": "2024-03-27T20:40:28.360475Z",
     "shell.execute_reply.started": "2024-03-27T20:37:04.532236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the fixed size\n",
    "new_shape = (128, 128, 128)\n",
    "# Function to load and resize NIfTI data\n",
    "def load_and_resize_nifti_data(file_path, new_shape):\n",
    "    try:\n",
    "        nifti_img = nib.load(file_path)\n",
    "        data = nifti_img.get_fdata()\n",
    "        resized_data = resize(data[..., 0], new_shape, anti_aliasing=True)  # Using only the first channel\n",
    "        return resized_data\n",
    "    except nib.FileHolderError:\n",
    "        print(f\"Error loading file: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Preprocess image data\n",
    "X_data = []\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(image_dir, img_file)\n",
    "    img_data = load_and_resize_nifti_data(img_path, new_shape)\n",
    "    if img_data is not None:\n",
    "        X_data.append(img_data)\n",
    "\n",
    "X_data = np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:40:28.365051Z",
     "iopub.status.busy": "2024-03-27T20:40:28.364215Z",
     "iopub.status.idle": "2024-03-27T20:41:44.584417Z",
     "shell.execute_reply": "2024-03-27T20:41:44.583419Z",
     "shell.execute_reply.started": "2024-03-27T20:40:28.365008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to load and resize NIfTI data\n",
    "def load_and_resize_nifti_data(file_path, new_shape):\n",
    "    try:\n",
    "        nifti_img = nib.load(file_path)\n",
    "        data = nifti_img.get_fdata()\n",
    "        resized_data = resize(data,new_shape, anti_aliasing=True)\n",
    "        return resized_data\n",
    "    except nib.FileHolderError:\n",
    "        print(f\"Error loading file: {file_path}\")\n",
    "        return None\n",
    "y_data = []\n",
    "for label_file in label_files:\n",
    "    label_path = os.path.join(label_dir, label_file)\n",
    "    label_data = load_and_resize_nifti_data(label_path, new_shape)\n",
    "    if label_data is not None:\n",
    "        y_data.append(label_data)\n",
    "\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:41:44.586463Z",
     "iopub.status.busy": "2024-03-27T20:41:44.586088Z",
     "iopub.status.idle": "2024-03-27T20:41:44.591726Z",
     "shell.execute_reply": "2024-03-27T20:41:44.590824Z",
     "shell.execute_reply.started": "2024-03-27T20:41:44.586423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print shapes for verification\n",
    "print(\"X_data shape:\", X_data.shape)  # Shape of preprocessed image data\n",
    "print(\"y_data shape:\", y_data.shape)  # Shape of preprocessed label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:42:06.381565Z",
     "iopub.status.busy": "2024-03-27T20:42:06.381199Z",
     "iopub.status.idle": "2024-03-27T20:42:06.709782Z",
     "shell.execute_reply": "2024-03-27T20:42:06.708952Z",
     "shell.execute_reply.started": "2024-03-27T20:42:06.381536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_data is your dataset with the shape (80, 128, 128, 128)\n",
    "first_image = y_data[10]  # This selects the first 3D volume\n",
    "\n",
    "# To visualize slices along the X, Y, and Z axes, choose the middle index for each.\n",
    "slice_x = first_image[first_image.shape[0] // 2, :, :]\n",
    "slice_y = first_image[:, first_image.shape[1] // 2, :]\n",
    "slice_z = first_image[:, :, first_image.shape[2] // 2]\n",
    "\n",
    "# Now, visualize these slices.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(slice_x, cmap='gray')\n",
    "axes[0].set_title('Slice along X-axis')\n",
    "axes[0].axis('off')  # Hide the axis for a cleaner look\n",
    "\n",
    "axes[1].imshow(slice_y, cmap='gray')\n",
    "axes[1].set_title('Slice along Y-axis')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(slice_z, cmap='gray')\n",
    "axes[2].set_title('Slice along Z-axis')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:42:26.600380Z",
     "iopub.status.busy": "2024-03-27T20:42:26.599547Z",
     "iopub.status.idle": "2024-03-27T20:42:26.606649Z",
     "shell.execute_reply": "2024-03-27T20:42:26.605757Z",
     "shell.execute_reply.started": "2024-03-27T20:42:26.600337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_size = 160\n",
    "test_size = 40\n",
    "\n",
    "# Split into train and test sets\n",
    "x_train = X_data[:train_size]\n",
    "y_train = y_data[:train_size]\n",
    "\n",
    "x_test = X_data[train_size:train_size + test_size]\n",
    "y_test = y_data[train_size:train_size + test_size]\n",
    "\n",
    "# Shapes of the train and test sets\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:42:32.643364Z",
     "iopub.status.busy": "2024-03-27T20:42:32.642497Z",
     "iopub.status.idle": "2024-03-27T20:42:53.461068Z",
     "shell.execute_reply": "2024-03-27T20:42:53.460274Z",
     "shell.execute_reply.started": "2024-03-27T20:42:32.643316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:42:55.400436Z",
     "iopub.status.busy": "2024-03-27T20:42:55.399495Z",
     "iopub.status.idle": "2024-03-27T20:42:55.893085Z",
     "shell.execute_reply": "2024-03-27T20:42:55.892073Z",
     "shell.execute_reply.started": "2024-03-27T20:42:55.400403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def list_available_gpus():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(\"Available GPUs:\")\n",
    "        for gpu in gpus:\n",
    "            print(gpu)\n",
    "    else:\n",
    "        print(\"No GPUs available.\")\n",
    "\n",
    "list_available_gpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Model Traning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T18:12:13.005164Z",
     "iopub.status.busy": "2024-03-25T18:12:13.004251Z",
     "iopub.status.idle": "2024-03-25T18:12:13.368187Z",
     "shell.execute_reply": "2024-03-25T18:12:13.367298Z",
     "shell.execute_reply.started": "2024-03-25T18:12:13.005129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, BatchNormalization, Dropout\n",
    "\n",
    "def unet_3d_model(input_shape=(128, 128, 128, 1)):\n",
    "    # Input layer\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "\n",
    "    # Bottom layer\n",
    "    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Dropout(0.5)(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = concatenate([UpSampling3D(size=(2, 2, 2))(conv4), conv3], axis=-1)\n",
    "    conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling3D(size=(2, 2, 2))(conv5), conv2], axis=-1)\n",
    "    conv6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    \n",
    "    up7 = concatenate([UpSampling3D(size=(2, 2, 2))(conv6), conv1], axis=-1)\n",
    "    conv7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv3D(1, (1, 1, 1), dtype=\"float32\", activation='sigmoid')(conv7)\n",
    "    \n",
    "    # Model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Create the 3D U-Net model\n",
    "model = unet_3d_model(input_shape=(128, 128, 128, 1))  # Adjust input_shape to match your data\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T18:12:19.921946Z",
     "iopub.status.busy": "2024-03-25T18:12:19.921292Z",
     "iopub.status.idle": "2024-03-25T19:14:20.694755Z",
     "shell.execute_reply": "2024-03-25T19:14:20.693486Z",
     "shell.execute_reply.started": "2024-03-25T18:12:19.921909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Define the Dice coefficient function\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    # Squeeze the prediction to remove the extra dimension if present\n",
    "    y_pred = tf.squeeze(y_pred, axis=-1)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "model.compile(optimizer=Adam(learning_rate=1e-2), loss='binary_crossentropy', metrics=[dice_coefficient])\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=60, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "73/80 ━━━━━━━━━━━━━━━━━━━━ 4s 646ms/step - dice_coefficient: 1.0590 - loss: -0.0874\n",
    "add Codeadd Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:41:56.205672Z",
     "iopub.status.busy": "2024-03-27T21:41:56.204844Z",
     "iopub.status.idle": "2024-03-27T21:41:56.213791Z",
     "shell.execute_reply": "2024-03-27T21:41:56.212767Z",
     "shell.execute_reply.started": "2024-03-27T21:41:56.205635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot the validation and training data separately\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['dice_coefficient']\n",
    "  val_accuracy = history.history['val_dice_coefficient']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "    \n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_dice_coefficient')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T19:18:29.561079Z",
     "iopub.status.busy": "2024-03-25T19:18:29.560734Z",
     "iopub.status.idle": "2024-03-25T19:18:30.310886Z",
     "shell.execute_reply": "2024-03-25T19:18:30.309773Z",
     "shell.execute_reply.started": "2024-03-25T19:18:29.561054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T19:19:48.469253Z",
     "iopub.status.busy": "2024-03-25T19:19:48.468806Z",
     "iopub.status.idle": "2024-03-25T19:19:48.753774Z",
     "shell.execute_reply": "2024-03-25T19:19:48.752755Z",
     "shell.execute_reply.started": "2024-03-25T19:19:48.469219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, BatchNormalization, Dropout\n",
    "\n",
    "def vnet_3d_model(input_shape=(128, 128, 128, 1)):\n",
    "    # Input layer\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv3D(16, (5, 5, 5), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv3D(32, (5, 5, 5), activation='relu', padding='same')(conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv3D(64, (5, 5, 5), activation='relu', padding='same')(pool1)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv4 = Conv3D(128, (5, 5, 5), activation='relu', padding='same')(conv3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv3D(256, (5, 5, 5), activation='relu', padding='same')(pool2)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv6 = Conv3D(512, (5, 5, 5), activation='relu', padding='same')(conv5)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    # Decoder\n",
    "    up7 = concatenate([UpSampling3D(size=(2, 2, 2))(conv6), conv4], axis=-1)\n",
    "    conv7 = Conv3D(128, (5, 5, 5), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv8 = Conv3D(64, (5, 5, 5), activation='relu', padding='same')(conv7)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling3D(size=(2, 2, 2))(conv8), conv2], axis=-1)\n",
    "    conv9 = Conv3D(32, (5, 5, 5), activation='relu', padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv10 = Conv3D(16, (5, 5, 5), activation='relu', padding='same')(conv9)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv3D(1, (1, 1, 1), dtype=\"float32\", activation='sigmoid')(conv10)\n",
    "\n",
    "    # Model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Create the VNet model\n",
    "model_Vnet = vnet_3d_model(input_shape=(128, 128, 128, 1))  # Adjust input_shape to match your data\n",
    "model_Vnet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T19:20:33.381637Z",
     "iopub.status.busy": "2024-03-25T19:20:33.381231Z",
     "iopub.status.idle": "2024-03-26T00:56:08.674307Z",
     "shell.execute_reply": "2024-03-26T00:56:08.673097Z",
     "shell.execute_reply.started": "2024-03-25T19:20:33.381607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_Vnet.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=[dice_coefficient])\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model_Vnet.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=60, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T00:56:08.677793Z",
     "iopub.status.busy": "2024-03-26T00:56:08.676969Z",
     "iopub.status.idle": "2024-03-26T00:56:09.386379Z",
     "shell.execute_reply": "2024-03-26T00:56:09.385440Z",
     "shell.execute_reply.started": "2024-03-26T00:56:08.677755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:47:51.642208Z",
     "iopub.status.busy": "2024-03-27T20:47:51.641866Z",
     "iopub.status.idle": "2024-03-27T20:47:51.959224Z",
     "shell.execute_reply": "2024-03-27T20:47:51.958339Z",
     "shell.execute_reply.started": "2024-03-27T20:47:51.642183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, BatchNormalization, Dropout\n",
    "\n",
    "def segnet_3d_model(input_shape=(128, 128, 128, 1)):\n",
    "    # Input layer\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "\n",
    "    # Bottom layer\n",
    "    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Dropout(0.5)(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = UpSampling3D(size=(2, 2, 2))(conv4)\n",
    "    conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = UpSampling3D(size=(2, 2, 2))(conv5)\n",
    "    conv6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    \n",
    "    up7 = UpSampling3D(size=(2, 2, 2))(conv6)\n",
    "    conv7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv3D(1, (1, 1, 1), dtype=\"float32\", activation='sigmoid')(conv7)\n",
    "    \n",
    "    # Model\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Create the 3D SegNet model\n",
    "model = segnet_3d_model(input_shape=(128, 128, 128, 1))  # Adjust input_shape to match your data\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T20:52:44.617156Z",
     "iopub.status.busy": "2024-03-27T20:52:44.616156Z",
     "iopub.status.idle": "2024-03-27T21:41:13.250659Z",
     "shell.execute_reply": "2024-03-27T21:41:13.249761Z",
     "shell.execute_reply.started": "2024-03-27T20:52:44.617119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    # Squeeze the prediction to remove the extra dimension if present\n",
    "    y_pred = tf.squeeze(y_pred, axis=-1)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice\n",
    "model.compile(optimizer=Adam(learning_rate=1e-2), loss='binary_crossentropy', metrics=[dice_coefficient])\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=60, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:42:21.394706Z",
     "iopub.status.busy": "2024-03-27T21:42:21.394320Z",
     "iopub.status.idle": "2024-03-27T21:42:21.975155Z",
     "shell.execute_reply": "2024-03-27T21:42:21.974281Z",
     "shell.execute_reply.started": "2024-03-27T21:42:21.394675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:43:31.744934Z",
     "iopub.status.busy": "2024-03-27T21:43:31.744539Z",
     "iopub.status.idle": "2024-03-27T21:43:32.224660Z",
     "shell.execute_reply": "2024-03-27T21:43:32.223760Z",
     "shell.execute_reply.started": "2024-03-27T21:43:31.744905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nii_image_path=\"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/BRATS_055.nii.gz\"\n",
    "nii_img = nib.load(nii_image_path)\n",
    "\n",
    "# Get the image data\n",
    "nii_data = nii_img.get_fdata()\n",
    "\n",
    "print(nii_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:43:35.466184Z",
     "iopub.status.busy": "2024-03-27T21:43:35.465815Z",
     "iopub.status.idle": "2024-03-27T21:43:35.472223Z",
     "shell.execute_reply": "2024-03-27T21:43:35.471231Z",
     "shell.execute_reply.started": "2024-03-27T21:43:35.466154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data=nii_data[...,0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:43:46.786014Z",
     "iopub.status.busy": "2024-03-27T21:43:46.785121Z",
     "iopub.status.idle": "2024-03-27T21:44:23.639770Z",
     "shell.execute_reply": "2024-03-27T21:44:23.638863Z",
     "shell.execute_reply.started": "2024-03-27T21:43:46.785976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_shape = (128, 128, 128)\n",
    "resized_data = resize(data, new_shape, anti_aliasing=True)\n",
    "# Ensure the resized image data has a single channel\n",
    "resized_data = np.expand_dims(resized_data, axis=-1)\n",
    "# Perform prediction\n",
    "prediction = model.predict(np.expand_dims(resized_data, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:44:23.641671Z",
     "iopub.status.busy": "2024-03-27T21:44:23.641362Z",
     "iopub.status.idle": "2024-03-27T21:44:23.647793Z",
     "shell.execute_reply": "2024-03-27T21:44:23.646814Z",
     "shell.execute_reply.started": "2024-03-27T21:44:23.641646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:44:33.668749Z",
     "iopub.status.busy": "2024-03-27T21:44:33.668334Z",
     "iopub.status.idle": "2024-03-27T21:44:33.675065Z",
     "shell.execute_reply": "2024-03-27T21:44:33.674070Z",
     "shell.execute_reply.started": "2024-03-27T21:44:33.668720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_data = prediction[0]\n",
    "predicted_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:44:56.031124Z",
     "iopub.status.busy": "2024-03-27T21:44:56.030758Z",
     "iopub.status.idle": "2024-03-27T21:44:56.041592Z",
     "shell.execute_reply": "2024-03-27T21:44:56.040772Z",
     "shell.execute_reply.started": "2024-03-27T21:44:56.031094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predicted_segmentation(nii_image_path):\n",
    "    # Load the NIfTI image\n",
    "    nii_img = nib.load(nii_image_path)\n",
    "\n",
    "    # Get the image data\n",
    "    nii_data = nii_img.get_fdata()\n",
    "\n",
    "    # Resize the image data to match the required input shape (128, 128, 128)\n",
    "    new_shape = (128, 128, 128)\n",
    "    resized_data = resize(nii_data, new_shape, anti_aliasing=True)\n",
    "\n",
    "    # Ensure the resized image data has a single channel\n",
    "    resized_data = np.expand_dims(resized_data, axis=-1)\n",
    "    # Perform prediction\n",
    "    prediction = model.predict(np.expand_dims(resized_data, axis=0))\n",
    "\n",
    "    # Extract the volume from the batch dimension\n",
    "    predicted_data = prediction[0]\n",
    "\n",
    "    # Plot a slice of the predicted volume (e.g., middle slice along each axis)\n",
    "    slice_x = predicted_data.shape[0] // 2\n",
    "    slice_y = predicted_data.shape[1] // 2\n",
    "    slice_z = predicted_data.shape[2] // 2\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot slices along the X-axis\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(predicted_data[slice_x, :, :, 0], cmap='gray')\n",
    "    plt.title('Slice along X-axis')\n",
    "\n",
    "    # Plot slices along the Y-axis\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(predicted_data[:, slice_y, :, 0], cmap='gray')\n",
    "    plt.title('Slice along Y-axis')\n",
    "    # Plot slices along the Z-axis\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_data[:, :, slice_z, 0], cmap='gray')\n",
    "    plt.title('Slice along Z-axis')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:45:10.371154Z",
     "iopub.status.busy": "2024-03-27T21:45:10.370273Z",
     "iopub.status.idle": "2024-03-27T21:45:10.378773Z",
     "shell.execute_reply": "2024-03-27T21:45:10.377797Z",
     "shell.execute_reply.started": "2024-03-27T21:45:10.371124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def actual_segmentation(label_path):\n",
    "    # Load the label image\n",
    "    label_img = nib.load(label_path)\n",
    "    \n",
    "    # Get the image data\n",
    "    actual_label = label_img.get_fdata()\n",
    "\n",
    "    # Plot a slice of the image (e.g., middle slice along each axis)\n",
    "    slice_x = actual_label.shape[0] // 2\n",
    "    slice_y = actual_label.shape[1] // 2\n",
    "    slice_z = actual_label.shape[2] // 2\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(actual_label[slice_x, :, :], cmap='gray')\n",
    "    plt.title('Slice along X-axis')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(actual_label[:, slice_y, :], cmap='gray')\n",
    "    plt.title('Slice along Y-axis')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(actual_label[:, :, slice_z], cmap='gray')\n",
    "    plt.title('Slice along Z-axis')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:52:42.313539Z",
     "iopub.status.busy": "2024-03-27T21:52:42.312788Z",
     "iopub.status.idle": "2024-03-27T21:52:42.423460Z",
     "shell.execute_reply": "2024-03-27T21:52:42.422459Z",
     "shell.execute_reply.started": "2024-03-27T21:52:42.313507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_path = \"/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/BRATS_055.nii.gz\"\n",
    "actual_segmentation(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:52:14.274496Z",
     "iopub.status.busy": "2024-03-27T21:52:14.273481Z",
     "iopub.status.idle": "2024-03-27T21:52:14.922481Z",
     "shell.execute_reply": "2024-03-27T21:52:14.921589Z",
     "shell.execute_reply.started": "2024-03-27T21:52:14.274458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_segmentation(\"/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/BRATS_055.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:46:43.656464Z",
     "iopub.status.busy": "2024-03-27T21:46:43.655621Z",
     "iopub.status.idle": "2024-03-27T21:46:59.613286Z",
     "shell.execute_reply": "2024-03-27T21:46:59.612311Z",
     "shell.execute_reply.started": "2024-03-27T21:46:43.656429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install celluloid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:46:59.615568Z",
     "iopub.status.busy": "2024-03-27T21:46:59.615239Z",
     "iopub.status.idle": "2024-03-27T21:47:11.921973Z",
     "shell.execute_reply": "2024-03-27T21:47:11.920756Z",
     "shell.execute_reply.started": "2024-03-27T21:46:59.615537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:47:11.924568Z",
     "iopub.status.busy": "2024-03-27T21:47:11.924219Z",
     "iopub.status.idle": "2024-03-27T21:47:11.955825Z",
     "shell.execute_reply": "2024-03-27T21:47:11.954952Z",
     "shell.execute_reply.started": "2024-03-27T21:47:11.924536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from celluloid import Camera\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:47:18.556104Z",
     "iopub.status.busy": "2024-03-27T21:47:18.554989Z",
     "iopub.status.idle": "2024-03-27T21:47:20.117403Z",
     "shell.execute_reply": "2024-03-27T21:47:20.116140Z",
     "shell.execute_reply.started": "2024-03-27T21:47:18.556069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the paths to the image and label files\n",
    "image_path = Path(\"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/BRATS_055.nii.gz\")\n",
    "label_path = Path(\"/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/BRATS_055.nii.gz\")\n",
    "\n",
    "# Load the image and label data\n",
    "image_data = nib.load(image_path).get_fdata()\n",
    "label_data = nib.load(label_path).get_fdata().astype(int)  # Class labels should not be handled as float64\n",
    "\n",
    "# Create the figure and camera object\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "# Iterate over slices in the z-axis\n",
    "for i in range(image_data.shape[2]):\n",
    "    # Display the CT scan slice\n",
    "    plt.imshow(image_data[:,:,i,1], cmap=\"bone\")\n",
    "    # Overlay the label mask with transparency\n",
    "    mask = np.ma.masked_where(label_data[:,:,i] == 0, label_data[:,:,i])\n",
    "    plt.imshow(mask, alpha=0.5)\n",
    "    camera.snap()  # Store the current slice\n",
    "\n",
    "# Animate the slices\n",
    "plt.tight_layout()\n",
    "animation = camera.animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T21:47:25.691245Z",
     "iopub.status.busy": "2024-03-27T21:47:25.690323Z",
     "iopub.status.idle": "2024-03-27T21:47:42.451849Z",
     "shell.execute_reply": "2024-03-27T21:47:42.451029Z",
     "shell.execute_reply.started": "2024-03-27T21:47:25.691209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T22:02:14.781001Z",
     "iopub.status.busy": "2024-03-27T22:02:14.779939Z",
     "iopub.status.idle": "2024-03-27T22:02:35.308956Z",
     "shell.execute_reply": "2024-03-27T22:02:35.307465Z",
     "shell.execute_reply.started": "2024-03-27T22:02:14.780963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the paths to the image and label files\n",
    "image_path = Path(\"/kaggle/working/extracted_data/Task01_BrainTumour/imagesTr/BRATS_055.nii.gz\")\n",
    "label_path = Path(\"/kaggle/working/extracted_data/Task01_BrainTumour/labelsTr/BRATS_055.nii.gz\")\n",
    "\n",
    "# Load the image and label data\n",
    "image_data = nib.load(image_path).get_fdata()\n",
    "label_data = nib.load(label_path).get_fdata().astype(int)  # Class labels should not be handled as float64\n",
    "\n",
    "# Create the figure and camera object\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "# Iterate over slices in the z-axis\n",
    "for i in range(image_data.shape[2]):\n",
    "    # Display the CT scan slice\n",
    "    plt.imshow(image_data[:,:,i,1], cmap=\"bone\")\n",
    "    # Overlay the label mask with transparency\n",
    "    mask = np.ma.masked_where(label_data[:,:,i] == 0, label_data[:,:,i])\n",
    "    plt.imshow(mask, alpha=0.5)\n",
    "    camera.snap()  # Store the current slice\n",
    "\n",
    "plt.tight_layout()\n",
    "animation = camera.animate()\n",
    "\n",
    "# Display the animation as HTML5 video\n",
    "HTML(animation.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
