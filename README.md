# ğŸ“˜ **README.md â€“ Brain Tumor Multi-Step Diagnosis Pipeline (Detection + VLM Reporting)**


## ğŸ§  Project Overview

This repository implements a **complete multi-step AI pipeline** for automated brain tumor analysis from MRI scans.
The system combines:

1. **A custom-trained tumor detection & classification model** (YOLO / Faster-RCNN / CNN)
2. **A feature extraction module** (tumor size, location, cropped ROI, etc.)
3. **A Vision-Language Model (VLM)** fine-tuned to generate **radiology-style reports**

All models are trained **from scratch**, including data preprocessing, augmentation, training loops, evaluation, and fine-tuning.

---

## ğŸ”¥ Features

* **Tumor classification** (Glioma, Meningioma, Pituitary, No Tumor)
* **Bounding box detection** (if YOLO / Faster-RCNN option is used)
* **Tumor region cropping & medically relevant feature extraction**
* **VLM-based radiology report generation** using structured inputs + image encodings
* **End-to-end training scripts** for all modules
* **Evaluation pipeline** with metrics (mAP, F1, BLEU/ROUGE for text quality)
* **Modular architecture** â†’ easy to swap models
* **FastAPI inference server** (optional)
* **Clean dataset schema and JSON annotation format**

---

## ğŸ— Project Architecture

```
brain-tumor-ai/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original datasets (BRATS, Kaggle, Figshare, etc.)
â”‚   â”œâ”€â”€ processed/          # Preprocessed MRI images
â”‚   â”œâ”€â”€ annotations/        # JSON annotations for detection + VLM
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detector/           # YOLO/FasterRCNN implementation & training
â”‚   â”œâ”€â”€ vlm/                # VLM fine-tuning scripts (Unsloth / vLLM)
â”‚   â”œâ”€â”€ feature_extractor/  # Tumor location, size, ROI crop
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train_detector.py
â”‚   â”œâ”€â”€ train_vlm.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ inference_pipeline.py
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ detector.yaml
â”‚   â”œâ”€â”€ vlm_config.json
â”‚   â”œâ”€â”€ dataset_schema.json
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb           # Dataset exploration
â”‚   â”œâ”€â”€ Detector_Training.ipynb
â”‚   â”œâ”€â”€ VLM_FineTune.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture_diagram.png
â”‚   â”œâ”€â”€ dataset_guidelines.md
â”‚   â”œâ”€â”€ vlm_prompting.md
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py              # FastAPI server
â”‚   â”œâ”€â”€ ui/                 # Optional frontend
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§© Pipeline Description

### **Step 1 â€” Tumor Detection & Classification**

You will train a model from scratch using PyTorch.
You can choose between:

* CNN classifier
* Faster-RCNN
* YOLOv8/Yolov12

**Output Example:**

```json
{
  "tumor_type": "Glioma",
  "confidence": 0.93,
  "bbox": [x1, y1, x2, y2]
}
```

---

### **Step 2 â€” Medical Feature Extraction**

Using the bounding box you compute:

* Tumor location (left/right hemisphere)
* Estimated size (mmÂ² or cmÂ²)
* Crop of tumor region
* Shape + intensity stats

**Output Example:**

```json
{
  "location": "Left frontal lobe",
  "size_mm": 24.7,
  "crop_path": "data/crops/image123.png"
}
```

---

### **Step 3 â€” VLM Radiology Reporting**

You fine-tune a Vision-Language Model using Unsloth or vLLM.

**Inputs to the VLM:**

* Original MRI
* Tumor crop
* Detected tumor class
* Extracted features

**Output:**
A radiology-style, structured report.

---

## ğŸ“¦ Dataset Requirements

This project supports multiple sources:

* **BRATS 2020/2021**
* **Kaggle Brain Tumor Dataset**
* **Figshare MRI datasets**

You must unify all datasets into the following JSON format:

### **dataset_schema.json**

```json
{
  "image": "path/to/mri.png",
  "label": "Glioma",
  "bbox": [100, 40, 350, 300],
  "extra_features": {
    "location": "Left temporal lobe",
    "size_mm": 27.1
  },
  "report": "Ground truth radiology report here."
}
```

---

## ğŸ‹ï¸ Training From Scratch

### **1ï¸âƒ£ Train the Tumor Detector**

```bash
python scripts/train_detector.py \
    --config configs/detector.yaml \
    --epochs 100 \
    --batch-size 16
```

**Quickstart for the new training script**

1. Install deps: `pip install torch torchvision pyyaml pillow`
2. Prepare `data/annotations/train.json` and `data/annotations/val.json` (list of records with `image`, `label`, and `bbox`).
3. Point `configs/detector.yaml` to your image root and label set. Set `task` to `classification` (ResNet18 head) or `detection` (FasterRCNN).
4. Run: `python scripts/train_detector.py --config configs/detector.yaml`

---

### **2ï¸âƒ£ Generate Features & Cropped Tumor Regions**

```bash
python scripts/preprocess.py
```

---

### **3ï¸âƒ£ Fine-Tune the VLM**

```bash
python scripts/train_vlm.py \
    --config configs/vlm_config.json \
    --epochs 5
```

---

## ğŸ§ª Evaluation

### **Detection Metrics**

* mAP (0.5 / 0.5:0.95)
* Precision / Recall
* Confusion Matrix

### **Text Report Metrics**

* BLEU
* ROUGE-L
* Medical factuality score (custom)

Run evaluation:

```bash
python scripts/evaluate.py
```

---

## ğŸš€ Inference Pipeline

For deployment, combine all steps:

```bash
python scripts/inference_pipeline.py \
    --image test/sample.png \
    --output report.json
```

Output example:

```json
{
  "tumor_type": "Pituitary",
  "features": { "size_mm": 18.4, "location": "Right side" },
  "report": "The scan demonstrates a pituitary macroadenoma..."
}
```

---

## ğŸŒ Optional: FastAPI Server

Start the API:

```bash
uvicorn app.api:app --reload
```

Send a request:

```bash
POST /analyze
```

---

## ğŸ“š Documentation

| Topic         | File                            |
| ------------- | ------------------------------- |
| Dataset rules | `docs/dataset_guidelines.md`    |
| VLM prompting | `docs/vlm_prompting.md`         |
| Architecture  | `docs/architecture_diagram.png` |

---

## ğŸ¤ Contributing

Pull requests are welcome!
Please open an issue to discuss improvements or bugs.

---

## ğŸ“„ License

MIT License â€” This project is fully open for research and educational use.

---

## â­ Acknowledgements

This project integrates:

* PyTorch
* Unsloth / vLLM
* YOLO / Faster-RCNN
* Medical imaging datasets (BRATS, Figshare)

